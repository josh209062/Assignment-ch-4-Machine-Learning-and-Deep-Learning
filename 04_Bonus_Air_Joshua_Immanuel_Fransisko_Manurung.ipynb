{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pada Soal Bonus ini saya mengerjakan technical challenges yang ketiga yaitu:  **Compare 3 configurations for the activation function. Show and\n",
        "explain your performance result.**\n"
      ],
      "metadata": {
        "id": "AwpjECJ3ENdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "1igk2WsK8pic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n"
      ],
      "metadata": {
        "id": "6yjUNOVs_ynC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Function\n"
      ],
      "metadata": {
        "id": "VpPezXtp0Wwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk menghindari penulisan model yang berulang-ulang, maka untuk bagian neural network design, Set hyperparameter, training serta model evaluation akan dimasukkan kedalam sebuah function."
      ],
      "metadata": {
        "id": "1A6cPgb70Z9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_nn(activation):\n",
        "\n",
        "  #Load Dataset MNIST dari Pytorch\n",
        "  transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "  train_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "  test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "  #Mendesain Neural Network\n",
        "  class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Model, self).__init__()\n",
        "      self.encoder1 = nn.Linear(28*28, 256)\n",
        "      self.encoder2 = nn.Linear(256, 128)\n",
        "      self.encoder3 = nn.Linear(128, 64)\n",
        "      self.encoder4 = nn.Linear(64, 32)\n",
        "      self.encoder5 = nn.Linear(32, 10)\n",
        "      self.activation = activation #Agar model dapat secara otomatis menggunakan activation function yang diinput ke function\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 28 * 28)\n",
        "      x = self.activation(self.encoder1(x))\n",
        "      x = self.activation(self.encoder2(x))\n",
        "      x = self.activation(self.encoder3(x))\n",
        "      x = self.activation(self.encoder4(x))\n",
        "      x = self.encoder5(x)\n",
        "      return x\n",
        "  model = Model()\n",
        "\n",
        "  #Set Hyperparameter\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  #Training Loop MNIST DataSets\n",
        "  start_time = time.time()\n",
        "  losses = []\n",
        "  print(f'Training MNIST Datasets using {activation} activation')\n",
        "  for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i%200 == 0:\n",
        "          print(f'Epoch : {epoch}, batch : {i}, loss : {loss.item()}')\n",
        "        losses.append(loss.detach().numpy())\n",
        "  total_time = time.time() - start_time\n",
        "  print(f'Finished Training using ({activation}) activation, in Durattion: {total_time/60} minutes.')\n",
        "  print(f'====================================================================================================')\n",
        "  print('')\n",
        "  print(f'====================================================================================================')\n",
        "\n",
        "  #Model Evaluation\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  predicted_labels = []\n",
        "  true_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "          predicted_labels.extend(predicted.numpy())\n",
        "          true_labels.extend(labels.numpy())\n",
        "\n",
        "  accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "  f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "  precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "  recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "  confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "  return {\n",
        "      'activation': activation,\n",
        "      'accuracy': accuracy,\n",
        "      'f1_score': f1,\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'confusion_matrix': confusion,\n",
        "      'duration': total_time\n",
        "  }"
      ],
      "metadata": {
        "id": "dYV0oF7P0yU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Menjalankan Fungsi"
      ],
      "metadata": {
        "id": "Q8Z6OHn25-VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#membuat variabel yang menyimpan fungsi aktivasi yang akan digunakan.\n",
        "#disini ada 3 fungsi aktivasi yang digunakan yaitu sigmoid, Tanh dan ReLU\n",
        "activation_functions = [nn.Sigmoid(), nn.Tanh(), nn.ReLU()]\n",
        "\n",
        "model_performances = [] #menyimpan hasil run fungsi yang telah dibuat sebelumnya\n",
        "\n",
        "\n",
        "#menjalankan fungsi build_model_nn dan menyimpan outputnya ke variabel model_performances\n",
        "for activation_function in activation_functions:\n",
        "  result = build_model_nn(activation_function)\n",
        "  model_performances.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHbHhF2k6C1L",
        "outputId": "e4d35449-e243-4797-88fa-7e26ce12f157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MNIST Datasets using Sigmoid() activation\n",
            "Epoch : 0, batch : 0, loss : 2.3310723304748535\n",
            "Epoch : 0, batch : 200, loss : 1.4959242343902588\n",
            "Epoch : 0, batch : 400, loss : 0.8760689496994019\n",
            "Epoch : 1, batch : 0, loss : 0.5416803956031799\n",
            "Epoch : 1, batch : 200, loss : 0.3893685042858124\n",
            "Epoch : 1, batch : 400, loss : 0.29255473613739014\n",
            "Epoch : 2, batch : 0, loss : 0.29812610149383545\n",
            "Epoch : 2, batch : 200, loss : 0.3325211703777313\n",
            "Epoch : 2, batch : 400, loss : 0.18727390468120575\n",
            "Epoch : 3, batch : 0, loss : 0.19136124849319458\n",
            "Epoch : 3, batch : 200, loss : 0.20256055891513824\n",
            "Epoch : 3, batch : 400, loss : 0.15395168960094452\n",
            "Epoch : 4, batch : 0, loss : 0.09814225882291794\n",
            "Epoch : 4, batch : 200, loss : 0.16047781705856323\n",
            "Epoch : 4, batch : 400, loss : 0.18687711656093597\n",
            "Epoch : 5, batch : 0, loss : 0.06021694839000702\n",
            "Epoch : 5, batch : 200, loss : 0.1251239776611328\n",
            "Epoch : 5, batch : 400, loss : 0.2283354252576828\n",
            "Epoch : 6, batch : 0, loss : 0.048351746052503586\n",
            "Epoch : 6, batch : 200, loss : 0.10539925843477249\n",
            "Epoch : 6, batch : 400, loss : 0.09865456819534302\n",
            "Epoch : 7, batch : 0, loss : 0.11469434946775436\n",
            "Epoch : 7, batch : 200, loss : 0.09569563716650009\n",
            "Epoch : 7, batch : 400, loss : 0.11134600639343262\n",
            "Epoch : 8, batch : 0, loss : 0.031108122318983078\n",
            "Epoch : 8, batch : 200, loss : 0.048135895282030106\n",
            "Epoch : 8, batch : 400, loss : 0.13437242805957794\n",
            "Epoch : 9, batch : 0, loss : 0.07264497876167297\n",
            "Epoch : 9, batch : 200, loss : 0.051035504788160324\n",
            "Epoch : 9, batch : 400, loss : 0.05807148292660713\n",
            "Finished Training using (Sigmoid()) activation, in Durattion: 2.170295302073161 minutes.\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Training MNIST Datasets using Tanh() activation\n",
            "Epoch : 0, batch : 0, loss : 2.2851505279541016\n",
            "Epoch : 0, batch : 200, loss : 0.3639554977416992\n",
            "Epoch : 0, batch : 400, loss : 0.2545255720615387\n",
            "Epoch : 1, batch : 0, loss : 0.1357056051492691\n",
            "Epoch : 1, batch : 200, loss : 0.20287445187568665\n",
            "Epoch : 1, batch : 400, loss : 0.14843112230300903\n",
            "Epoch : 2, batch : 0, loss : 0.039691004902124405\n",
            "Epoch : 2, batch : 200, loss : 0.15034787356853485\n",
            "Epoch : 2, batch : 400, loss : 0.09956783056259155\n",
            "Epoch : 3, batch : 0, loss : 0.2260347157716751\n",
            "Epoch : 3, batch : 200, loss : 0.07021885365247726\n",
            "Epoch : 3, batch : 400, loss : 0.09937858581542969\n",
            "Epoch : 4, batch : 0, loss : 0.07896767556667328\n",
            "Epoch : 4, batch : 200, loss : 0.197676882147789\n",
            "Epoch : 4, batch : 400, loss : 0.13969257473945618\n",
            "Epoch : 5, batch : 0, loss : 0.061517275869846344\n",
            "Epoch : 5, batch : 200, loss : 0.047036658972501755\n",
            "Epoch : 5, batch : 400, loss : 0.14550265669822693\n",
            "Epoch : 6, batch : 0, loss : 0.11795255541801453\n",
            "Epoch : 6, batch : 200, loss : 0.16281916201114655\n",
            "Epoch : 6, batch : 400, loss : 0.05240977928042412\n",
            "Epoch : 7, batch : 0, loss : 0.04445864260196686\n",
            "Epoch : 7, batch : 200, loss : 0.04331004619598389\n",
            "Epoch : 7, batch : 400, loss : 0.21429818868637085\n",
            "Epoch : 8, batch : 0, loss : 0.13887672126293182\n",
            "Epoch : 8, batch : 200, loss : 0.0817025825381279\n",
            "Epoch : 8, batch : 400, loss : 0.048877645283937454\n",
            "Epoch : 9, batch : 0, loss : 0.058370426297187805\n",
            "Epoch : 9, batch : 200, loss : 0.07249341905117035\n",
            "Epoch : 9, batch : 400, loss : 0.11836054176092148\n",
            "Finished Training using (Tanh()) activation, in Durattion: 2.1659130851427713 minutes.\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Training MNIST Datasets using ReLU() activation\n",
            "Epoch : 0, batch : 0, loss : 2.3177623748779297\n",
            "Epoch : 0, batch : 200, loss : 0.33242127299308777\n",
            "Epoch : 0, batch : 400, loss : 0.34365078806877136\n",
            "Epoch : 1, batch : 0, loss : 0.2007662057876587\n",
            "Epoch : 1, batch : 200, loss : 0.37373557686805725\n",
            "Epoch : 1, batch : 400, loss : 0.17723460495471954\n",
            "Epoch : 2, batch : 0, loss : 0.19937577843666077\n",
            "Epoch : 2, batch : 200, loss : 0.2524293065071106\n",
            "Epoch : 2, batch : 400, loss : 0.175432488322258\n",
            "Epoch : 3, batch : 0, loss : 0.0716143324971199\n",
            "Epoch : 3, batch : 200, loss : 0.11691458523273468\n",
            "Epoch : 3, batch : 400, loss : 0.13147512078285217\n",
            "Epoch : 4, batch : 0, loss : 0.1424403339624405\n",
            "Epoch : 4, batch : 200, loss : 0.07083609700202942\n",
            "Epoch : 4, batch : 400, loss : 0.0933682918548584\n",
            "Epoch : 5, batch : 0, loss : 0.03130420297384262\n",
            "Epoch : 5, batch : 200, loss : 0.12339390814304352\n",
            "Epoch : 5, batch : 400, loss : 0.13673439621925354\n",
            "Epoch : 6, batch : 0, loss : 0.13430850207805634\n",
            "Epoch : 6, batch : 200, loss : 0.02506265416741371\n",
            "Epoch : 6, batch : 400, loss : 0.1375138908624649\n",
            "Epoch : 7, batch : 0, loss : 0.16162696480751038\n",
            "Epoch : 7, batch : 200, loss : 0.1637323796749115\n",
            "Epoch : 7, batch : 400, loss : 0.07293601334095001\n",
            "Epoch : 8, batch : 0, loss : 0.12552747130393982\n",
            "Epoch : 8, batch : 200, loss : 0.006068908143788576\n",
            "Epoch : 8, batch : 400, loss : 0.014079468324780464\n",
            "Epoch : 9, batch : 0, loss : 0.038846325129270554\n",
            "Epoch : 9, batch : 200, loss : 0.007322868797928095\n",
            "Epoch : 9, batch : 400, loss : 0.019418127834796906\n",
            "Finished Training using (ReLU()) activation, in Durattion: 2.1579176704088847 minutes.\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan print hasil dari performance model yang telah di jalankan\n",
        "for result in model_performances:\n",
        "  print(f'Model ({result[\"activation\"]} Activation):')\n",
        "  print(f'Accuracy: {result[\"accuracy\"] * 100:.2f}%')\n",
        "  print(f'F1 Score: {result[\"f1_score\"]:.2f}')\n",
        "  print(f'Precision: {result[\"precision\"]:.2f}')\n",
        "  print(f'Recall: {result[\"recall\"]:.2f}')\n",
        "  print(f'Duration: {(result[\"duration\"]/60):.2f} Minutes')\n",
        "  print('Confusion Matrix:')\n",
        "  print(result['confusion_matrix'])\n",
        "  print()\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ojfWuZ_XZv",
        "outputId": "14ef0a07-b369-4200-d5c3-d7120bd78391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model (Sigmoid() Activation):\n",
            "Accuracy: 96.91%\n",
            "F1 Score: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.97\n",
            "Duration: 2.17 Minutes\n",
            "Confusion Matrix:\n",
            "[[ 965    0    1    1    1    7    2    1    1    1]\n",
            " [   0 1128    2    1    0    1    2    0    1    0]\n",
            " [   0    2 1003   10    4    3    0    7    3    0]\n",
            " [   0    5    4  976    0   12    0    6    5    2]\n",
            " [   2    0    1    0  964    0    6    2    0    7]\n",
            " [   4    0    1    9    1  864    3    4    4    2]\n",
            " [   4    2    6    3    8   11  922    0    2    0]\n",
            " [   2   15   10    3    0    0    0  990    0    8]\n",
            " [   1    1    3    7    5   13    2    2  937    3]\n",
            " [   3    3    0    3   31   13    0   13    1  942]]\n",
            "\n",
            "\n",
            "Model (Tanh() Activation):\n",
            "Accuracy: 96.79%\n",
            "F1 Score: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.97\n",
            "Duration: 2.17 Minutes\n",
            "Confusion Matrix:\n",
            "[[ 963    1    0    0    0    6    5    2    3    0]\n",
            " [   0 1123    1    1    0    1    1    0    7    1]\n",
            " [   7    2  991   13    1    1    2    8    7    0]\n",
            " [   1    0    2  986    0    5    0    3    3   10]\n",
            " [   2    4    2    0  944    2    6    1    3   18]\n",
            " [   2    2    2   18    0  846    7    1    8    6]\n",
            " [   3    4    4    1    5    7  924    1    9    0]\n",
            " [   0    8    8   12    0    2    0  980    3   15]\n",
            " [   1    0    3   12    1    6    2    5  942    2]\n",
            " [   2    2    0    6    8    6    1    3    1  980]]\n",
            "\n",
            "\n",
            "Model (ReLU() Activation):\n",
            "Accuracy: 97.03%\n",
            "F1 Score: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.97\n",
            "Duration: 2.16 Minutes\n",
            "Confusion Matrix:\n",
            "[[ 966    0    0    2    0    2    5    3    1    1]\n",
            " [   0 1121    1    2    0    2    5    0    3    1]\n",
            " [   3    1  994   10    2    3    5    9    5    0]\n",
            " [   0    0    0  995    0    3    0    4    4    4]\n",
            " [   1    0    0    1  943    3   13    4    1   16]\n",
            " [   3    0    0   16    0  860    3    2    2    6]\n",
            " [   4    1    1    1    3    7  940    0    1    0]\n",
            " [   0   11    6    3    1    0    0 1006    0    1]\n",
            " [   4    1    0    9    4   11    9    6  925    5]\n",
            " [   3    2    0   12   13    4    2   18    2  953]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kesimpulan"
      ],
      "metadata": {
        "id": "8aKh6W7ZChlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil run model neural network yang telah dibuat diatas menggunakan 3 buah aktivasi, dapat kita lihat bahwasanya tidak ada perbedaan yang signifikan dari tingkat akurasi, F1 Score, Precision, Recall, durasi, serta confusion matrix yang dihasilkan. Hal ini dapat dilihat melalui rincian dibawah.\n",
        "1. Model Neural Network dengan fungsi aktivasi ReLU memiliki performa yang sedikit lebih baik dibandingkan 2 model lainnya, dimana ia memiliki akurasi sebesar 97.03%, durasi training selama2.16 Menit, serta F1 score, precision dan recall sebesar 0.97% **(Saat saya melakukan Training)**\n",
        "2. Model Neural Network dengan fungsi aktivasi Sigmoid memiliki performa diperingkat kedua, dimana ia memiliki akurasi sebesar 96.91%, durasi training selama2.17 Menit, serta F1 score, precision dan recall sebesar 0.97 **(Saat saya melakukan Training)**\n",
        "3. Model Neural Network dengan fungsi aktivasi Tanh memiliki performa diperingkat ketiga, dimana ia memiliki akurasi sebesar 96.79%, durasi training selama2.17 Menit, serta F1 score, precision dan recall sebesar 0.97 **(Saat saya melakukan Training)**"
      ],
      "metadata": {
        "id": "WvTcoiu_Cjfo"
      }
    }
  ]
}